{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPeYQNte0y5+nlgB1rROQF6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/udathateja/my_work/blob/main/pyspark_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkNRb0r7_hTV"
      },
      "source": [
        "from google.colab import drive, files\n",
        "#drive.flush_and_unmount()\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeypkAKO_wOY"
      },
      "source": [
        "!ls \"/content/drive/My Drive/Colab Notebooks\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdmAULWl_wJW"
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://apachemirror.wuchna.com/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!tar -xvzf spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install -U pyarrow\n",
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFXd5NKybw6A"
      },
      "source": [
        "import scipy.io,sys,os,logging,functools,findspark,tempfile,urllib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import tkinter as tk\n",
        "from random import randint\n",
        "from time import sleep\n",
        "from threading import *\n",
        "from pyspark.sql import SparkSession"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE0TkqkZ_wGQ"
      },
      "source": [
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZimfaKO4_wCx"
      },
      "source": [
        "findspark.init()\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "#spark = SparkSession.builder.master(\"local\").appName(\"MyAppName\").getOrCreate()\n",
        "#spark = SparkSession.builder.appName(\"MyAppName\").getOrCreate()\n",
        "#spark.conf.set(\"spark.executor.memory\", \"4g\")\n",
        "SparkContext.setSystemProperty('spark.executor.memory', '4g')\n",
        "#spark.conf.set(\"spark.driver.memory\", \"4g\")\n",
        "SparkContext.setSystemProperty(\"spark.driver.memory\", \"4g\")\n",
        "#spark.conf.set(\"spark.memory.fraction\", \"0.9\")\n",
        "SparkContext.setSystemProperty(\"spark.memory.fraction\", \"0.9\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WG9hCwJP4z4"
      },
      "source": [
        "#BASE_DIR = '/tmp'\n",
        "#OUTPUT_FILE = os.path.join(BASE_DIR, 'credit_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy_Ox002QRoG"
      },
      "source": [
        "credit_data, headers = urllib.request.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data\")\n",
        "os.rename(credit_data, \"/tmp/credit_data.csv\")\n",
        "credit_df = spark.read.option(\"inferschema\", \"true\").csv(\"/tmp/credit_data.csv\", header=False)\n",
        "credit_df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUTWfJTbkMpX"
      },
      "source": [
        "OR Also"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF22L33q_v3I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82564483-a9f9-44e5-d574-e7a5c4923e09"
      },
      "source": [
        "#spark_data = spark.read.format('csv').options(header='true').load(\"/content/sample_data/california_housing_train.csv\")\n",
        "#spark_data.show(5, truncate=False)\n",
        "df1=spark.read.csv(path=\"/tmp/credit_data.csv\", header=True, inferSchema=True)\n",
        "#df1.printSchema()\n",
        "df1.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-----+-----+---+---+---+---+----+---+---+---+---+---+-----+---+---+\n",
            "|  b|30.83|   02|  u| g4|  w|  v|1.25| t8| t9| 01|  f|g12|00202|014|  +|\n",
            "+---+-----+-----+---+---+---+---+----+---+---+---+---+---+-----+---+---+\n",
            "|  a|58.67| 4.46|  u|  g|  q|  h|3.04|  t|  t|  6|  f|  g|00043|560|  +|\n",
            "|  a|24.50|  0.5|  u|  g|  q|  h| 1.5|  t|  f|  0|  f|  g|00280|824|  +|\n",
            "|  b|27.83| 1.54|  u|  g|  w|  v|3.75|  t|  t|  5|  t|  g|00100|  3|  +|\n",
            "|  b|20.17|5.625|  u|  g|  w|  v|1.71|  t|  f|  0|  f|  s|00120|  0|  +|\n",
            "|  b|32.08|  4.0|  u|  g|  m|  v| 2.5|  t|  f|  0|  t|  g|00360|  0|  +|\n",
            "+---+-----+-----+---+---+---+---+----+---+---+---+---+---+-----+---+---+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBvcjgLH_v0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c37872a-54c9-4e4c-d1ba-97e4b7596598"
      },
      "source": [
        "df2 = spark.createDataFrame([{\"spark on\":\"jupiter\"} for x in range(1000)])\n",
        "df2.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+\n",
            "|spark on|\n",
            "+--------+\n",
            "| jupiter|\n",
            "| jupiter|\n",
            "| jupiter|\n",
            "| jupiter|\n",
            "| jupiter|\n",
            "+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muyEmo_u_vuV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}